{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Assignment 3\n",
    "## Group 6: Gabriea Groenewegen Van Der Weijden & Arnaud Haaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 10 preperation:\n",
    "1. Download the data from https://www.kaggle.com/c/home-depot-product-searchrelevance/data and unzip all files. You now have a directory with four csv files and one docx\n",
    "file.\n",
    "2. Import the csv files in Python as separate Pandas dataframes.\n",
    "3. Read the information on the task and the data. Provide a task definition in your report for\n",
    "assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary packages.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv files into dataframes.\n",
    "df_test = pd.read_csv(\"test.csv\", encoding=\"ISO-8859-1\")\n",
    "df_train = pd.read_csv(\"train.csv\", encoding=\"ISO-8859-1\")\n",
    "df_attr = pd.read_csv(\"attributes.csv\")\n",
    "df_sample_sub = pd.read_csv(\"sample_submission.csv\")\n",
    "df_pro_desc = pd.read_csv(\"product_descriptions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relevance</th>\n",
       "      <th>Occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.33</td>\n",
       "      <td>3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.67</td>\n",
       "      <td>6780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.75</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.00</td>\n",
       "      <td>11730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.25</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.33</td>\n",
       "      <td>16060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.50</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.67</td>\n",
       "      <td>15202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.75</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.00</td>\n",
       "      <td>19125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    relevance  Occurences\n",
       "0        1.00        2105\n",
       "1        1.25           4\n",
       "2        1.33        3006\n",
       "3        1.50           5\n",
       "4        1.67        6780\n",
       "5        1.75           9\n",
       "6        2.00       11730\n",
       "7        2.25          11\n",
       "8        2.33       16060\n",
       "9        2.50          19\n",
       "10       2.67       15202\n",
       "11       2.75          11\n",
       "12       3.00       19125"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe with all the product-query combinations.\n",
    "df_proq = df_train[[\"product_title\", \"search_term\"]]\n",
    "\n",
    "# Creating a dataframe with all the unique product-query combinations.\n",
    "un_comb = df_proq.groupby([\"product_title\", \"search_term\"]).size().reset_index()\n",
    "\n",
    "# Calculating the unique number of products in the training data.\n",
    "uni_prod = df_train['product_title'].nunique()\n",
    "\n",
    "# Calculating the two most occuring products in the training data.\n",
    "two_most = df_train.groupby(\"product_title\").size().reset_index().rename(columns={0: \"Occurences\"}).sort_values(by=[\"Occurences\"], ascending=False).head(2)\n",
    "\n",
    "# Calculating the descriptive statistics for the relevance values (mean, median,standard deviation) in the training data.\n",
    "mean_relevance = round(df_train['relevance'].mean(), 2)\n",
    "median_relevance = round(df_train['relevance'].median(), 2)\n",
    "std_relevance = round(df_train['relevance'].std(), 2)\n",
    "\n",
    "#Preparing the data in ordr to show a histogram or boxplot of the distribution of relevance values in the training data.\n",
    "df_rel_val = df_train.groupby(\"relevance\").size().reset_index().rename(columns={0: \"Occurences\"})\n",
    "df_rel_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The copy of the model.\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "num_train = df_train.shape[0]\n",
    "\n",
    "def str_stemmer(s):\n",
    "\treturn \" \".join([stemmer.stem(word) for word in s.lower().split()])\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "\treturn sum(int(str2.find(word)>=0) for word in str1.split())\n",
    "\n",
    "\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "\n",
    "df_all = pd.merge(df_all, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "df_all['search_term'] = df_all['search_term'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_title'] = df_all['product_title'].map(lambda x:str_stemmer(x))\n",
    "df_all['product_description'] = df_all['product_description'].map(lambda x:str_stemmer(x))\n",
    "\n",
    "df_all['len_of_query'] = df_all['search_term'].map(lambda x:len(x.split())).astype(np.int64)\n",
    "\n",
    "df_all['product_info'] = df_all['search_term']+\"\\t\"+df_all['product_title']+\"\\t\"+df_all['product_description']\n",
    "\n",
    "df_all['word_in_title'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[1]))\n",
    "df_all['word_in_description'] = df_all['product_info'].map(lambda x:str_common_word(x.split('\\t')[0],x.split('\\t')[2]))\n",
    "\n",
    "df_all = df_all.drop(['search_term','product_title','product_description','product_info'],axis=1)\n",
    "\n",
    "df_train = df_all.iloc[:num_train]\n",
    "df_test = df_all.iloc[num_train:]\n",
    "id_test = df_test['id']\n",
    "\n",
    "y_train = df_train['relevance'].values\n",
    "X_train = df_train.drop(['id','relevance'],axis=1).values\n",
    "X_test = df_test.drop(['id','relevance'],axis=1).values\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 11\n",
    "1. Make a 80-20 split of the training set, using 80% for training and 20% for testing using the\n",
    "train_test_split function in sklearn.\n",
    "2. Evaluate the predictions on the test set in terms of Root Mean Squared Error (RMSE). Verify\n",
    "that your result is close to 0.48. \n",
    "\n",
    "The obtained result is your baseline result. Make sure that you use the same train-test split in every\n",
    "run. Be aware that lower RMSE scores are better.\n",
    "\n",
    "3. Evaluate the matching without stemming for search terms, product titles, and product\n",
    "descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) for clf: 0.4849\n"
     ]
    }
   ],
   "source": [
    "# Splitting the train data into 80% of training and 20% testing.\n",
    "\n",
    "# We are trying to predict the relevance of the tools.\n",
    "X = df_train.drop(columns=['relevance', 'id', 'product_uid'])\n",
    "y = df_train['relevance']\n",
    "\n",
    "# Split 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# print(\"X_train shape:\", X_train.shape)\n",
    "# print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "\n",
    "\"\"\" Evaluating the predictions on the test set in terms of Root mean squared error. \"\"\"\n",
    "\n",
    "# Fitting the model.\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set.\n",
    "y_pred_clf = clf.predict(X_test)\n",
    "rmse_clf = np.sqrt(mean_squared_error(y_test, y_pred_clf))\n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE) for clf:\", round(rmse_clf, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-reading the csv files into dataframes because the previous ones have been changed.\n",
    "df_test = pd.read_csv(\"test.csv\", encoding=\"ISO-8859-1\")\n",
    "df_train = pd.read_csv(\"train.csv\", encoding=\"ISO-8859-1\")\n",
    "df_attr = pd.read_csv(\"attributes.csv\")\n",
    "df_sample_sub = pd.read_csv(\"sample_submission.csv\")\n",
    "df_pro_desc = pd.read_csv(\"product_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the matching without stemming for search terms, product titles, and product descriptions.\n",
    "\n",
    "# Rebuild from original inputs\n",
    "df_all_nostem = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "df_all_nostem = pd.merge(df_all_nostem, df_pro_desc, how='left', on='product_uid')\n",
    "\n",
    "# Lowercasing only (no stemming)\n",
    "df_all_nostem['search_term'] = df_all_nostem['search_term'].map(lambda x: x.lower())\n",
    "df_all_nostem['product_title'] = df_all_nostem['product_title'].map(lambda x: x.lower())\n",
    "df_all_nostem['product_description'] = df_all_nostem['product_description'].map(lambda x: x.lower())\n",
    "\n",
    "# Feature engineering\n",
    "df_all_nostem['len_of_query'] = df_all_nostem['search_term'].map(lambda x: len(x.split())).astype(np.int64)\n",
    "df_all_nostem['product_info'] = df_all_nostem['search_term'] + \"\\t\" + df_all_nostem['product_title'] + \"\\t\" + df_all_nostem['product_description']\n",
    "\n",
    "def str_common_word(str1, str2):\n",
    "    return sum(int(str2.find(word) >= 0) for word in str1.split())\n",
    "\n",
    "df_all_nostem['word_in_title'] = df_all_nostem['product_info'].map(lambda x: str_common_word(x.split('\\t')[0], x.split('\\t')[1]))\n",
    "df_all_nostem['word_in_description'] = df_all_nostem['product_info'].map(lambda x: str_common_word(x.split('\\t')[0], x.split('\\t')[2]))\n",
    "\n",
    "# Drop intermediate text columns\n",
    "df_all_nostem = df_all_nostem.drop(['search_term', 'product_title', 'product_description', 'product_info'], axis=1)\n",
    "\n",
    "# Split\n",
    "df_train_nostem = df_all_nostem.iloc[:num_train]\n",
    "df_test_nostem = df_all_nostem.iloc[num_train:]\n",
    "id_test = df_test_nostem['id']\n",
    "\n",
    "y_train = df_train_nostem['relevance'].values\n",
    "X_train = df_train_nostem.drop(['id', 'relevance'], axis=1).values\n",
    "X_test = df_test_nostem.drop(['id', 'relevance'], axis=1).values\n",
    "\n",
    "# Train and predict\n",
    "rf = RandomForestRegressor(n_estimators=15, max_depth=6, random_state=0)\n",
    "clf = BaggingRegressor(rf, n_estimators=45, max_samples=0.1, random_state=25)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Save result\n",
    "pd.DataFrame({\"id\": id_test, \"relevance\": y_pred}).to_csv('submission_no_stemming.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) for clf without stemming: 0.4949\n"
     ]
    }
   ],
   "source": [
    "# We are trying to predict the relevance of the tools.\n",
    "X = df_train_nostem.drop(columns=['relevance', 'id', 'product_uid'])\n",
    "y = df_train_nostem['relevance']\n",
    "\n",
    "# Split 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# print(\"X_train shape:\", X_train.shape)\n",
    "# print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "\"\"\" Evaluating the predictions on the test set in terms of Root mean squared error. \"\"\"\n",
    "\n",
    "# Fitting the models\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 2. Predict on the test set\n",
    "y_pred_clf = clf.predict(X_test)\n",
    "\n",
    "# 3. Compute RMSE\n",
    "rmse_clf = np.sqrt(mean_squared_error(y_test, y_pred_clf))\n",
    "print(\"Root Mean Squared Error (RMSE) for clf without stemming:\", round(rmse_clf, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the matching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add features for the query-product matching and evaluate the efficacy of each feature. A few\n",
    "suggestions are:\n",
    "• Add features for matching query terms to the information in attributes.csv\n",
    "• Use the structure of the attribute-value pairs to make better informed features\n",
    "• Replace the simple term count matching functions with other overlap weights. You might\n",
    "consider using the function TfidfVectorizer in sklearn or the text similarity function in the\n",
    "spacy package.\n",
    "Be creative: use any information from the queries and products that might improve the matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 12\n",
    "1. Find three other regression models in the sklearn documentation and compare these for the task,\n",
    "both in quality (RMSE) and processing time. A comparison of the results for four regression models are part of the report for assignment 3.\n",
    "2. Select the model that works the best. You will now optimize the model’s hyperparameters. In Sklearn\n",
    "there are some very simple hyper parameter tuning methods: https://scikitlearn.org/stable/modules/grid_search.html . It is also possible to use more advanced methods such\n",
    "as Bayesian Optimization (https://github.com/wangronin/Bayesian-Optimization/ ).\n",
    "Make sure you are not optimizing on your test set; you will need to use cross validation on the train\n",
    "set (e.g using the function RandomizedSearchCV)\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_Ass3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
